---
title: 'Distributional semantics as a source of visual knowledge: Commentary on Kim et al. (2019)'
author: "Molly Lewis, Martin Zettersten, and Gary Lupyan"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: hide
    number_sections: yes
    theme: paper
    toc: yes
    toc_float: no
subtitle: Supplementary Information
---

******
******

```{r setup, include = F}
# load packages
library(tidyverse)
library(knitr)
library(here)
library(dendextend)
library(ggdendro)
library(RColorBrewer)
library(cowplot)
library(broom)
library(R.matlab)
library(heatmaply)


opts_chunk$set(echo = F, message = F, warning = F, 
               error = F, cache = F, tidy = F, fig.height = 4.5)

theme_set(theme_classic())
options(shiny.sanitize.errors = FALSE)
```  

<a href="https://github.com/mllewis/keb_2019_reanalysis" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm</style>

This document was created from an R markdown file. The repository for the project can be found here: https://github.com/mllewis/keb_2019_reanalysis.


# Card Sorting Task
We estimated the similarity between animals based on distributional statistics using a word embedding model trained on English Wikipedia (Bojanowski, et al. 2016). As in the human task from Kim et al. (2019), we estimated the similarity between animals based on different conceptual dimensions (color, shape, and texture). For each dimension, we identified all unique words participants generated as labels for their piles during the card sorting task (we removed a small set of items that were dimension-irrelevant, e.g. "farm"). We then calculated the pairwise cosine distance between each animal and dimension label. For example, for the color dimension, participants produced "brown", "black", and "pink" as descriptors for their piles (among many other labels). So, for each animal, we calculated the distance between brown, black and pink using the word embedding vectors. These distances created a "color" vector for each animal (in this case of length 3). We then used these vectors to calculate the Euclidean distance between each animal based on its color vector. These distances provide an estimate of the overall similarity between two animals in terms of color based on language statistics alone. We repeated this same procedure for the shape and texture dimensions.

## Dimension labels
The table below presents the description labels used for each of the three dimensions (color, shape, and texture).
```{r}
DESCRIPTIONS_PATHS <- list(here("data/processed/animal_color_descriptions.csv"),
                           here("data/processed/animal_shape_descriptions.csv"),
                           here("data/processed/animal_texture_descriptions.csv"))

map_df(DESCRIPTIONS_PATHS, read_csv) %>%
  rename(dimension = type) %>%
  select(dimension, word) %>%
  DT::datatable()
```


## Pairwise Correlations{.tabset}
In the Main Text, we report correlations between the pairwise animals distances for each of the three dimensions (language vs. human/gorund truth). These are presented more fully below.

```{r, fig.width = 8, fig.height = 4}
### Shape-texture-color plot ###
LANG_ANIMAL_DISTANCE_COLOR <- here("data/processed/animal_color_distances_language_wiki.csv")
LANG_ANIMAL_DISTANCE_SHAPE<- here("data/processed/animal_shape_distances_language_wiki.csv")
LANG_ANIMAL_DISTANCE_TEXTURE <- here("data/processed/animal_texture_distances_language_wiki.csv")

# human
TIDY_HUMAN_PATH <- here("data/processed/tidy_human_data.csv") 
language_data <- read_csv(LANG_ANIMAL_DISTANCE_COLOR) %>%
  left_join(read_csv(LANG_ANIMAL_DISTANCE_SHAPE), by  = c("animal1", "animal2")) %>%
  left_join(read_csv(LANG_ANIMAL_DISTANCE_TEXTURE),by  = c("animal1", "animal2"))  %>%
  mutate_if(is.numeric, ~-.x )

human_data <- read_csv(TIDY_HUMAN_PATH)  

full_sim_data_wide2 <-  full_join(language_data, human_data,
                                  by = c("animal1", "animal2")) %>%
  spread(similarity_type, human_similarity) %>%
  filter(animal1 < animal2) 

language_long <- full_sim_data_wide2 %>%
  select(contains("animal"), contains("language")) %>%
  distinct() %>%
  gather(similarity_type, language_similarity, -animal1, -animal2) %>%
  rowwise() %>%
  mutate(similarity_type = str_split(similarity_type, "dist_")[[1]][2])
  
human_long <- full_sim_data_wide2 %>%
  select(contains("animal"), contains("human"), participant_type) %>%
  gather(similarity_type, human_similarity, -animal1, -animal2, -participant_type) %>%
  rowwise() %>%
  mutate(similarity_type = str_split(similarity_type, "similarity_")[[1]][2],
         similarity_type = case_when(similarity_type == "skin" ~ "texture", 
                                     TRUE ~ similarity_type)) %>%
  filter(similarity_type %in% c("color", "shape", "texture")) 
  
long_df <- full_join(language_long, human_long)

ggplot(long_df, aes(x = language_similarity, y = human_similarity, color = participant_type))+
  geom_point(alpha = .4) + 
  ggtitle("Predicting Human Similarity") +
  ylab("human similarity (KEB card sorting task)") +
  xlab("language similarity (cosine distance)") +
  facet_wrap(~ similarity_type, scales = "free_x") +
  geom_smooth(method = "lm")

# taxonomic
TAXONOMIC_PATH <- here("data/raw/taxonomy_matrix.mat")
taxonomic_data <- R.matlab::readMat(TAXONOMIC_PATH)[[2]]  
LABELS <- c("shark", "swan", "flamingo", "pigeon", "crow", "elephant", 
            "mammoth", "sloth", "beaver", "gorilla", "bat", "rhino", 
            "zebra", "llama", "hippo", "killerwhale", "dolphin", "giraffe",
            "sheep", "goat", "deer", "pig", "boar", "lion", "panther", "cheetah",
            "skunk", "panda", "polarbear", "grizzly") %>% rev() # from SI fig s2
colnames(taxonomic_data) <- LABELS
rownames(taxonomic_data) <- LABELS
taxonomic_long <- taxonomic_data %>%
  as.data.frame() %>%
  rownames_to_column("animal1") %>%
  gather("animal2", "similarity", -animal1) %>%
  mutate(sim_type = "taxonomic_similarity")
LANGUAGE_PATH_WIKI <- here("data/processed/animal_distances_wiki.csv")
language_data_wiki <- read_csv(LANGUAGE_PATH_WIKI) %>%
  spread(word2, language_similarity) %>%
  select(-word1)
all_corrs_mat_langs_wiki <- as.matrix(language_data_wiki)
rownames(all_corrs_mat_langs_wiki) <- colnames(language_data_wiki)
language_long_wiki <- all_corrs_mat_langs_wiki %>%
  as.data.frame() %>%
  rownames_to_column("animal1") %>%
  gather("animal2", "similarity", -animal1)  %>%
  mutate(sim_type = "lang_wiki_similarity")
```

```{r, fig.width = 5, fig.height = 4}
taxo_full <- bind_rows(taxonomic_long, language_long_wiki) %>%
  filter(animal1 < animal2) %>%
  spread(sim_type, similarity)  %>%
  mutate(participant_type = "Ground Truth") 

ggplot(taxo_full, aes(x = lang_wiki_similarity, y = -taxonomic_similarity))+
  geom_point(alpha = .4) + 
  ggtitle("Predicting Taxonomic Similarity") +
  ylab("taxonomic similarity (as reported in KEB)") +
  xlab("language similarity (cosine distance)") +
  geom_smooth(method = "lm")
```

For consistency, taxonomic distances are reported here in terms of similarity (1 - evolutionary distance).

```{r}
dimension_corr <- long_df %>%
  group_by(participant_type, similarity_type) %>%
  nest() %>%
  mutate(temp = map(data, ~ tidy(cor.test(.$language_similarity,
                                          .$human_similarity, method = "spearman"))),
         n = map(data, nrow)) %>%
  select(-data) %>%
  unnest() 

taxo_corr <- taxo_full %>%
  group_by(participant_type) %>%
  nest() %>%
  mutate(temp = map(data, ~ tidy(cor.test(.$lang_wiki_similarity,
                                          -.$taxonomic_similarity, method = "spearman"))),
         n = map(data, nrow),
         similarity_type = "taxonomy")  %>%
  select(-data) %>%
  unnest() 

cor_df <- dimension_corr %>%
  bind_rows(taxo_corr) %>%
  select(-method, -alternative, -statistic) %>%
  mutate(similarity_type = fct_relevel(similarity_type, "taxonomy", "shape", "texture"),
         participant_type = str_to_title(participant_type))  %>%
  arrange(similarity_type)

kable(cor_df,digits = 5)
```

Notably, in a regression predicting human similarity with both taxonomic and linguistic similarity, both measures predict independent variance in human judgements for all three dimensions. 

### Color
```{r}
lm_df <- full_sim_data_wide2 %>%
  left_join(taxonomic_long %>% 
              rename("taxonomic_sim" = similarity) %>% select(-sim_type)) %>%
  mutate(taxonomic_sim = 1-taxonomic_sim)

lm(human_similarity_color~ language_similarity_simple_dist_color+  
    taxonomic_sim  + participant_type,  data = lm_df %>% mutate_if(is.numeric, scale)) %>%
  summary() %>%
  tidy()%>%
  kable(digits=5)
```

### Texture
```{r}

lm(human_similarity_color~ language_similarity_simple_dist_texture +  
    taxonomic_sim  + participant_type,
   data = lm_df %>% mutate_if(is.numeric, scale)) %>%
  summary() %>%
  tidy()%>%
  kable(digits=5)
```

### Shape
```{r}
lm(human_similarity_color ~ language_similarity_simple_dist_shape +  
    taxonomic_sim  + participant_type,  
   data = lm_df %>% mutate_if(is.numeric, scale)) %>%
  summary() %>%
  tidy( )%>%
  kable(digits=5)
```


## Basic Clusterings {.tabset} 
```{r}
get_hclust <- function(current_sims){
  wide_sims <- current_sims %>%
    select(animal1, animal2, similarity_value) %>%
    spread(animal1, similarity_value) %>%
    select(-animal2)
  
  wide_sims_mat <- as.matrix(wide_sims)
  rownames(wide_sims_mat) <- colnames(wide_sims)
  
  #replace NA's with 0's along the diagonal
  wide_sims_mat[is.na(wide_sims_mat)] <- 0
  
  wide_sims_mat %>%
    dist() %>%
    hclust()
}

TIDY_HUMAN_WIKI_DATA <- here("data/processed/tidy_human_wiki_language_data.csv")

all_data <- read_csv(TIDY_HUMAN_WIKI_DATA)

all_hclusts <- all_data %>%
  filter(!(knowledge_type %in% c("habitat", "food"))) %>%
  group_by(knowledge_source, knowledge_type) %>%
  nest() %>%
  mutate(hclusts = map(data, get_hclust)) %>%
  select(-data)
```


We clustered the resulting pairwise animal similarities for each of the three dimensions. The dendrograms below present hierarchical cluster analysis of human judgements of similarity and language-based estimates of similarity for each dimension. Dendrograms were produced using the ggdendro (de Vries & Ripley, 2016) and dendextend (Galili, 2015) packages in R. 

### Shape

```{r, fig.show = "hold", out.width = "33%", echo = F}
plot_basic_dendro <- function(current_df, kt, ks){
  lang <- current_df %>%
     filter(knowledge_type == kt,
            knowledge_source == ks) %>%
     pull(hclusts) 
  
  ggdendro::ggdendrogram(lang[[1]], rotate = T) +
            ggtitle(paste0(str_to_title(ks), " Similarity ", str_to_title(kt)))
}

plot_basic_dendro(all_hclusts, "shape", "language")
plot_basic_dendro(all_hclusts, "shape", "blind")
plot_basic_dendro(all_hclusts, "shape", "sighted")

```

### Texture

```{r, fig.show = "hold", out.width = "33%", height = 4}
plot_basic_dendro(all_hclusts, "texture", "language")
plot_basic_dendro(all_hclusts, "texture", "blind")
plot_basic_dendro(all_hclusts, "texture", "sighted")
```

### Color

```{r, fig.show = "hold", out.width = "33%"}
plot_basic_dendro(all_hclusts, "color", "language")
plot_basic_dendro(all_hclusts, "color", "blind")
plot_basic_dendro(all_hclusts, "color", "sighted")
```

## Entanglement Comparisons {.tabset}

Entanglement is a measure of how well the labels of two dendrograms are aligned. Entanglement values range from 0 (fully aligned labels) to 1 (fully mismatched labels). Entanglement is computed by numbering the labels (1 to the total number of labels) of each tree, and then computing the L-norm distance between these two vectors.

Below, we show pairwise comparisons of human judgement-based (blind and sighted participants) and language-based dendrograms in so-called tanglegrams, after using the untangle() method from the R package dendextend to minimize the amount of entanglement, i.e. to optimize the alignment of the labels from the two dendrograms without altering the underlying cluster structure. We also plot the minimum entanglement values found for each pairwise comparison (lower equals better alignment of the labels).

### Shape

```{r, fig.show = "hold", out.width = "50%"}
plot_tanglegrams <- function(current_df, kt){
  current_dends <- current_df %>%
  filter(knowledge_type == kt,
         knowledge_source %in% c("language", "blind")) %>%
  mutate(dendros = map(hclusts, as.dendrogram)) %>%
  pull(dendros)

dendlist(current_dends[[1]], current_dends[[2]]) %>%
  untangle(method = "step2side") %>%
  tanglegram(axes = F, color_lines = "black", 
             common_subtrees_color_lines = FALSE, 
             highlight_branches_lwd = FALSE,
             highlight_distinct_edges = FALSE,
             margin_inner = 5.7,
             main_left = "LANGUAGE",
             main_right = "BLIND") 

current_dends <- current_df %>%
  filter(knowledge_type == kt,
         knowledge_source %in% c("language", "sighted")) %>%
  mutate(dendros = map(hclusts, as.dendrogram)) %>%
  pull(dendros)

dendlist(current_dends[[1]], current_dends[[2]]) %>%
  untangle(method = "step2side") %>%
  tanglegram(axes = F, color_lines="black", 
             common_subtrees_color_lines = FALSE, 
             highlight_branches_lwd = FALSE,
             highlight_distinct_edges = FALSE,
             margin_inner = 5.7,
             main_left = "LANGUAGE",
             main_right = "SIGHTED") 
}

plot_tanglegrams(all_hclusts, "shape")
```

### Texture

```{r, fig.show = "hold", out.width = "50%"}
plot_tanglegrams(all_hclusts, "texture")
```

### Color

```{r, fig.show = "hold", out.width = "50%"}
plot_tanglegrams(all_hclusts, "color")
```

### Entanglement Values

```{r, fig.height = 4, fig.width = 8}
##read in data frame of cluster similarity values (created in 01_compute_cluster_similarity_values.R)
CLUSTER_PATH <- here("data/processed/cluster_similarity_values.csv")
cluster_similarity_values <- read_csv(CLUSTER_PATH)

#process into shorter dataframe
cluster_similarity <- cluster_similarity_values %>%
  rowwise() %>% 
  mutate(knowledge_source = paste(sort(c(as.character(knowledge_source_1), 
                                    as.character(knowledge_source_2))), collapse = "_")) %>%  
  ungroup() %>%
  group_by(knowledge_type,knowledge_source) %>%
  select(-knowledge_source_1,-knowledge_source_2) %>%
  summarise_all(min)

ggplot(cluster_similarity, aes(knowledge_source,entangle_step2side,fill=knowledge_source))+
  geom_bar(stat="identity")+
  ylim(0,1)+
  facet_wrap(~knowledge_type)+
  theme(legend.position="none", 
        axis.text.x  = element_text(angle=90, vjust=0.5))+
  scale_x_discrete(limits=c("blind_sighted","language_sighted","blind_language"),
                   labels=c("Blind \nto Sighted", "Language \nto Sighted","Language \nto Blind"))+
  scale_fill_brewer(palette="Set1")+
  ylab("Entanglement")+
  xlab("Clustering Comparison")
```


## Indices of Similarity between Clusterings{.tabset}

We also computed two indices of the similarity between the clusterings derived from human (blind and sighted participant data) and language-based similarity ratings for color, shape and texture: the Fowlkes-Mallows Index and the adjusted Rand index.

### FM-Index (z-scored)

The Fowlkes-Mallows Index (FM-Index) is computed by comparing the two hierarchical clustering trees cut at a specific level k (i.e. split into k different clusters based on the hierarchical cluster). It varies from 0 to 1, with higher values indicating greater similarity. Intuitively, the FM-Index captures the degree to which two labels tend to fall in the same cluster in both tree 1 and tree 2. The Fowlkes-Mallows index is computed as the geometric mean of the ratio of the total number of labels sharing the same cluster in both trees to the number of labels sharing the same cluster in tree 1 and the ratio of the total number of labels sharing the same cluster in both trees to the number of labels sharing the same cluster in tree 2. The FM-Index of two given hierarchical clusterings is then compared to the expected value of the FM-Index under the hypothesis of no relation between the two clusterings.

The plots depict the z-scored FM-Index for each pairwise comparison of the hierarchical cluster trees derived from the human judgement and language similarity data, after cutting the trees into _k_ = 5, 10, 15, and 20 clusters. The dashed line shows the critical value at $\alpha = .05$ assuming a one-sided hypothesis test ($z = 1.645$, i.e. the z-score with a tail area of .05).

```{r, fig.height = 5, fig.width = 4}
cluster_similarity_Z_FM <- cluster_similarity %>%
  select(knowledge_type,knowledge_source,Z_FM_5,Z_FM_10,Z_FM_15, Z_FM_20) %>%
  gather(cluster_num,Z_FM, Z_FM_5:Z_FM_20) %>%
  mutate(cluster_num=as.numeric(as.character(str_remove(cluster_num, "Z_FM_"))))

ggplot(cluster_similarity_Z_FM, aes(x = knowledge_source, y = Z_FM, fill = knowledge_source)) +
    geom_bar(stat="identity")+
    scale_x_discrete(name="",
                 limits=c("blind_sighted","language_sighted","blind_language"),
               labels=c("Blind \nto Sighted", "Language \nto Sighted","Language \nto Blind"))+
    scale_y_continuous(limits=c(-2,16))+
    geom_hline(yintercept=1.645, linetype="dashed")+
    scale_fill_brewer(palette="Set1")+
    ylab("FM Index (Z-score)")+
    xlab("Clustering Comparison")+
    facet_grid(cluster_num ~ knowledge_type)+
    theme(legend.position = "none", 
          axis.text.x  = element_text(angle=90, vjust=0.5,size=8))
```

### Adjusted Rand Index

The Rand index is the ratio of the number of pairs of labels on which two clusterings agree (i.e. the number of pairs of labels in the same cluster in both trees and the number of pairs of labels in different clusters in both trees) to the total number of label pairs. The adjusted Rand index (here using Hubert and Arabie's method) corrects the Rand index for the number of groupings one might expect by chance alone. An adjusted Rand index of 0 indicates two clusterings have a Rand index that matches the expected value for random groupings, with higher and lower values indicating higher- or lower-than-chance level similarity between the two clusterings.

The plots depict the adjusted Rand index for each pairwise comparison of the hierarchical cluster trees derived from the human judgement and language similarity data, after cutting the trees into _k_ = 5, 10, 15, and 20 clusters.

```{r, fig.height = 5, fig.width = 4}
cluster_similarity_adjustedRand <- cluster_similarity %>%
  select(knowledge_type, knowledge_source,
         adjustedRand_5, adjustedRand_10, adjustedRand_15, adjustedRand_20) %>%
  gather(cluster_num,adjustedRand, adjustedRand_5:adjustedRand_20) %>%
  mutate(cluster_num = as.numeric(as.character(str_remove(cluster_num, "adjustedRand_"))))

ggplot(cluster_similarity_adjustedRand, aes(x = knowledge_source, y = adjustedRand, fill = knowledge_source)) +
    geom_bar(stat ="identity")+
    scale_x_discrete(name="",
                 limits = c("blind_sighted","language_sighted","blind_language"),
                 labels = c("Blind \nto Sighted", "Language \nto Sighted","Language \nto Blind"))+
    scale_y_continuous(limits=c(-0.2,1))+
    scale_fill_brewer(palette="Set1")+
    ylab("Adjusted Rand Index")+
    xlab("Clustering Comparison")+
    facet_grid(cluster_num ~ knowledge_type) +
    theme(legend.position = "none", axis.text.x  = element_text(angle=90, vjust=0.5,size=8))
```

# Feature Choice Task (Texture)

In this analyis (corresponding to Fig. 1B in the Main Text), we used language data to predict human responses from a task where participants had to indicate whether each of the 30 animals had a texture of either fur, feathers, scales, or skin. 

```{r}
TIDY_HUMAN_TEXTURE <- here("data/processed/tidy_human_texture_response.csv")
LANGUAGE_SIMILARITY <- here("data/processed/animal_texture_langauge_distances_with_anchors.csv")

human_data_sim <- read_csv(TIDY_HUMAN_TEXTURE) %>%
  rename(similarity = prop)
language_data_sim  <- read_csv(LANGUAGE_SIMILARITY) %>%
  rename(texture = anchor,
         similarity = language_similarity)  %>%
  mutate(group = "Language")

animal_order <- c("goldfish", "snake", "crocodile", "lizard", "eel", "shark", "turtle", "toad", "dolphin", "frog", "worm", "elephant", "hippo", "rhino", "pig", "platypus", "seal","ferret", "gorilla", "sheep", "fox", "bear", "horse", "donkey", "cat", "penguin", "ostrich","flamingo", "peacock", "pigeon")
```

Figure 6b from Kim, Elli and Bendny (2019; KEB) is reproduced on the left below. To predict these data from distributional language statistics, we estimated the cosine distance between each animal and each texture using a model trained on English Wikipedia (Bojanowski, et al., 2016). On the right below, the cosine distance between each animal and each texture is shown. The most frequently selected/similiar texture is indicated in red. 

```{r}
TIDY_HUMAN_TEXTURE <- here("data/processed/tidy_human_texture_response.csv")
LANGUAGE_SIMILARITY <- here("data/processed/animal_texture_langauge_distances_with_anchors.csv")

human_data <- read_csv(TIDY_HUMAN_TEXTURE) %>%
  rename(similarity = prop) %>%
  select(-correct)

ground_truth <- read_csv(TIDY_HUMAN_TEXTURE)  %>%
  distinct(animal, texture, correct) %>%
  filter(correct == 1) %>%
  rename(ground_truth_texture = texture) %>%
  select(-correct)

language_data  <- read_csv(LANGUAGE_SIMILARITY) %>%
  filter(set_id == 0) %>%
  select(-set_id) %>%
  rename(texture = anchor)  

language_and_human_df<- left_join(human_data, language_data)

language_correct <- language_and_human_df %>%
  distinct(animal, texture, language_similarity) %>%
  group_by(animal) %>%
  filter(language_similarity == max(language_similarity)) %>%
  select(-contains("similarity")) %>%
  rename(language_texture = texture) %>%
  mutate(language_correct = "correct")

human_correct <- language_and_human_df %>%
  group_by(group, animal) %>%
  filter(similarity == max(similarity)) %>%
  select(-contains("similarity")) %>%
  slice(1)  %>% # get rid of one case where there's a tie (go with Kim et al. judgement) 
  spread(group, texture) %>%
  rename(CB_texture = CB, S_texture = S)

human_correct_for_plotting <- human_correct %>%
  gather(group, texture, -animal) %>%
  mutate(group = fct_recode(group, 
                            "Blind"  = "CB_texture",
                            "Sighted" = "S_texture"),
         human_correct = "correct")
```

```{r, fig.width = 8}
all_data <- bind_rows(human_data_sim, language_data_sim) %>%
    mutate(group = fct_relevel(group, "S", "CB", "Language"),
           group = fct_recode(group, "Sighted" = "S", "Blind" = "CB"))  %>%
  left_join(human_correct_for_plotting) %>%
  left_join(language_correct %>% 
              rename(texture = "language_texture") %>% 
              mutate(group = "Language"))  %>%
  mutate(animal = fct_relevel(animal,  animal_order),
         texture = fct_relevel(texture, "scales", "skin", "fur", "feathers"))

p1 <- all_data %>%
  filter(group != "Language") %>%
  ggplot(aes(x = texture, y = fct_rev(animal), fill = similarity, 
             color = human_correct))  +
  geom_tile(size = 1, aes(width=0.9, height=0.9)) +
  facet_wrap(~group) +
  scale_color_manual(values = c("red", "white"), guide = F) +
  ylab("animal") +
  scale_fill_gradient(low = "white", high = "black", limits = c(0,1))  +
  theme_classic()+
  theme(legend.position = "bottom")
```

```{r, fig.height = 5, width = 9}
p2 <-  all_data %>%
  filter(group == "Language") %>%
  ggplot(aes(x = texture, y = fct_rev(animal), fill = similarity, 
             color = language_correct))  +
  geom_tile(size = 1, aes(width=0.9, height=0.9)) +
  facet_wrap(~group) +
  scale_color_manual(values = c("red", "white"), guide = F) +
  ylab("animal") +
  scale_fill_gradient(low = "white", high = "black")  +
  theme_classic() +
  theme(legend.position = "bottom")

cowplot::plot_grid(p1, p2, ncol = 2, label_size = 16, rel_widths = c(1.8,1))
```

We calculated an accuracy score by identifying the most similar texture for each animal for the language and human data  and then calculating the proportion of animals for which the language estimates correctly predict the human responses as well as the objectively "correct" responses. These accuracy scores are presented below.

```{r}
accuracy_table <- full_join(language_correct, human_correct) %>%
  left_join(ground_truth) %>%
  mutate(CB_correct = CB_texture == language_texture,
         S_correct = S_texture == language_texture,
         gt_correct = ground_truth_texture == language_texture) %>%
  select(animal, contains("correct"), -language_correct) %>%
  gather("group", "value", -animal) %>%
  group_by(group) %>%
  nest() %>%
  mutate(temp = map(data, ~ binom.test(sum(.x$value), nrow(.x), p = .25) %>% tidy())) %>%
  select(-data) %>%
  unnest() %>%
  mutate(se = sqrt((estimate*(1-estimate))/parameter),
         group = fct_recode(group, "Blind" = "CB_correct", "Sighted" = "S_correct", "Ground Truth" = "gt_correct"),
         group = fct_relevel(group, "Ground Truth", "Sighted", "Blind"))

kable(accuracy_table,digits=5)

```

# Replication on Second Corpus{.tabset}
We replicated the pattern of results reported in the Main Text on a second corpus: A model trained on Google News (Mikolov, et al. 2013). Presented below are each of the key analyses using these embeddings. 

## Card Sorting Task
Below is the analog to Fig. 1A in the Main Text shown for a model trained on Google News (rather than the Wikipedia Corpus). 

```{r, fig.height = 3}
LANG_ANIMAL_DISTANCE_COLOR <- here("data/processed/animal_color_distances_language_google.csv")
LANG_ANIMAL_DISTANCE_SHAPE<- here("data/processed/animal_shape_distances_language_google.csv")
LANG_ANIMAL_DISTANCE_TEXTURE <- here("data/processed/animal_texture_distances_language_google.csv")

TIDY_HUMAN_PATH <- here("data/processed/tidy_human_data.csv") 
language_data <- read_csv(LANG_ANIMAL_DISTANCE_COLOR) %>%
  left_join(read_csv(LANG_ANIMAL_DISTANCE_SHAPE), by  = c("animal1", "animal2")) %>%
  left_join(read_csv(LANG_ANIMAL_DISTANCE_TEXTURE),by  = c("animal1", "animal2"))  %>%
  mutate_if(is.numeric, ~-.x )

human_data <- read_csv(TIDY_HUMAN_PATH) 
full_sim_data <- full_join(language_data, human_data, by = c("animal1", "animal2"))   

human_data_wide <- human_data %>%
  unite("measure", c("participant_type", "similarity_type")) %>%
  spread(measure, human_similarity)

full_sim_data_wide2 <-  full_join(language_data, human_data,
                                  by = c("animal1", "animal2"))    %>%
  spread(similarity_type, human_similarity) %>%
  filter(animal1 < animal2)

color_cors <- full_sim_data_wide2 %>%
  group_by(participant_type) %>%
  nest() %>%
  mutate(temp = map(data, ~ tidy(cor.test(.$language_similarity_simple_dist_color,
                                          .$human_similarity_color, method = "spearman"))),
         n = map(data, nrow),
         dimension = "Color") %>%
  select(-data) %>%
  unnest() 

texture_cors <- full_sim_data_wide2 %>%
  group_by(participant_type) %>%
  nest() %>%
  mutate(temp = map(data, ~ tidy(cor.test(.$language_similarity_simple_dist_texture,
                                          .$human_similarity_skin, method = "spearman"))),
         n = map(data, nrow),
         dimension = "Skin Texture") %>%
  select(-data) %>%
  unnest() 

shape_cors <- full_sim_data_wide2 %>%
  group_by(participant_type) %>%
  nest() %>%
  mutate(temp = map(data, ~ tidy(cor.test(.$language_similarity_simple_dist_shape,
                                          .$human_similarity_shape, method = "spearman"))),
         n = map(data, nrow),
         dimension = "Shape") %>%
  select(-data) %>%
  unnest()

TAXONOMIC_PATH <- here("data/raw/taxonomy_matrix.mat")
taxonomic_data <- R.matlab::readMat(TAXONOMIC_PATH)[[2]]  
LABELS <- c("shark", "swan", "flamingo", "pigeon", "crow", "elephant", 
            "mammoth", "sloth", "beaver", "gorilla", "bat", "rhino", 
            "zebra", "llama", "hippo", "killerwhale", "dolphin", "giraffe",
            "sheep", "goat", "deer", "pig", "boar", "lion", "panther", "cheetah",
            "skunk", "panda", "polarbear", "grizzly") %>% rev() # from SI fig s2
colnames(taxonomic_data) <- LABELS
rownames(taxonomic_data) <- LABELS
taxonomic_long <- taxonomic_data %>%
  as.data.frame() %>%
  rownames_to_column("animal1") %>%
  gather("animal2", "similarity", -animal1) %>%
  mutate(sim_type = "taxonomic_similarity")
LANGUAGE_PATH_WIKI <- here("data/processed/animal_distances_wiki.csv")
language_data_wiki <- read_csv(LANGUAGE_PATH_WIKI) %>%
  spread(word2, language_similarity) %>%
  select(-word1)
all_corrs_mat_langs_wiki <- as.matrix(language_data_wiki)
rownames(all_corrs_mat_langs_wiki) <- colnames(language_data_wiki)
language_long_wiki <- all_corrs_mat_langs_wiki %>%
  as.data.frame() %>%
  rownames_to_column("animal1") %>%
  gather("animal2", "similarity", -animal1)  %>%
  mutate(sim_type = "lang_wiki_similarity")

taxo_corr <- bind_rows(taxonomic_long, language_long_wiki) %>%
  filter(animal1 < animal2) %>%
  spread(sim_type, similarity)  %>%
  mutate(participant_type = "Ground Truth") %>%
  group_by(participant_type) %>%
  nest() %>%
  mutate(temp = map(data, ~ tidy(cor.test(.$lang_wiki_similarity,
                                          -.$taxonomic_similarity, method = "spearman"))),
         n = map(data, nrow),
         dimension = "Taxonomy")  %>%
  select(-data) %>%
  unnest() 

cor_df <- color_cors %>%
  bind_rows(texture_cors) %>%
  bind_rows(shape_cors) %>%
  bind_rows(taxo_corr) %>%
  select(-method, -alternative, -statistic) %>%
  mutate(se = 1/sqrt(n-3),
         estimate_se_l = estimate - se,
         estimate_se_h = estimate + se,
         dimension = fct_relevel(dimension, "Taxonomy", "Shape", "Skin Texture"),
         participant_type = str_to_title(participant_type)) %>%
  rowwise() %>%
  mutate(sig = case_when(p.value < .01 ~ "**",
                         p.value < .05 ~ "*",
                         TRUE ~ ""))

ggplot(cor_df, aes(x = fct_rev(participant_type), y = estimate, fill = participant_type)) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_grid(~dimension, drop = T, scales="free_x",space = "free_x") +
  xlab("Language as predictor of...") +
  geom_text(aes(y = estimate + .07, label = sig), size = 6) +
  geom_linerange(aes(ymin = estimate_se_l, ymax = estimate_se_h)) +
  theme_classic(base_size = 13) +
  scale_fill_manual(values = c( "#0345E1", "yellow","#DB3A26")) +
  scale_y_continuous(
    expand = expand_scale(mult = c(0, 0.05)),
    name = "Fisher's Z-transformed rho",
    limits = c(0, .42)) +
  theme(legend.position = "none")
```


## Feature Choice Task (Texture)

Below is the analog to Fig. 1B in the Main Text shown for a model trained on Google News (rather than the Wikipedia Corpus). 

```{r, fig.height = 3, fig.width = 4}
TIDY_HUMAN_TEXTURE <- here("data/processed/tidy_human_texture_response.csv")
LANGUAGE_SIMILARITY <- here("data/processed/animal_texture_langauge_distances_google.csv")

human_data <- read_csv(TIDY_HUMAN_TEXTURE) %>%
  rename(similarity = prop) %>%
  select(-correct)

ground_truth <- read_csv(TIDY_HUMAN_TEXTURE)  %>%
  distinct(animal, texture, correct) %>%
  filter(correct == 1) %>%
  rename(ground_truth_texture = texture) %>%
  select(-correct)

language_data  <- read_csv(LANGUAGE_SIMILARITY)

language_and_human_df <- left_join(human_data, language_data)

language_correct <- language_and_human_df %>%
  distinct(animal, texture, language_similarity) %>%
  group_by(animal) %>%
  filter(language_similarity == max(language_similarity)) %>%
  select(-contains("similarity")) %>%
  rename(language_texture = texture)

human_correct <- language_and_human_df %>%
  group_by(group, animal) %>%
  filter(similarity == max(similarity)) %>%
  select(-contains("similarity")) %>%
  slice(1)  %>% # get rid of one case where there's a tie (go with Kim et al. judgement) 
  spread(group, texture) %>%
  rename(CB_texture = CB, S_texture = S)

accuracy_table <- full_join(language_correct, human_correct) %>%
  left_join(ground_truth) %>%
  mutate(CB_correct = CB_texture == language_texture,
         S_correct = S_texture == language_texture,
         gt_correct = ground_truth_texture == language_texture) %>%
  select(animal, contains("correct")) %>%
  gather("group", "value", -animal) %>%
  group_by(group) %>%
  nest() %>%
  mutate(temp = map(data, ~ binom.test(sum(.x$value), nrow(.x), p = .25) %>% tidy())) %>%
  select(-data) %>%
  unnest() %>%
  mutate(se = sqrt((estimate*(1-estimate))/parameter),
         group = fct_recode(group, "Blind" = "CB_correct", "Sighted" = "S_correct",
                            "Ground Truth" = "gt_correct"),
         sig = case_when(p.value < .01 ~ "**", p.value < .05 ~ '*', TRUE ~ ""),
         group = fct_relevel(group, "Ground Truth", "Sighted", "Blind"))

ggplot(accuracy_table, aes(x = group, y = estimate, fill = group)) +
  geom_bar(stat = "identity", position = "dodge") +
  ylab("Skin Texture Type\nProportion Correct") +
  xlab("Language as predictor of...") +
  geom_hline(aes(yintercept = .25), linetype = 2) +
  geom_text(aes(y = estimate + .15, label = sig), size = 6) +
  #ggtitle("Language Predictions in Texture Feature Task") +
  geom_linerange(aes(ymin = estimate - se , ymax = estimate + se )) +
  theme_classic(base_size = 13) +
  scale_fill_manual(values = rev(c("#0345E1", "#DB3A26", "yellow"))) +
  scale_y_continuous(
    expand = expand_scale(mult = c(0, 0.05))) +
  theme(legend.position = "none")
```


# Bedny et al. (2019) Data
```{r}
BEDNY_DATA <- here("data/raw/datalong_CBSAMT.csv")
bedny_data <- read_csv(BEDNY_DATA)

sim_ratings <-bedny_data %>%
  filter(C1 == "Light", C2 == "Light") %>%
  select(contains("V"), contains("_")) %>%
  rename(word1 = V1,
         word2 = V2) %>%
  gather("subject_id", "raw_similarity", -word1, -word2) %>%
  group_by(subject_id) %>%
  mutate(scale_similarity = scale(raw_similarity),
         norm_similarity = (scale_similarity - min(scale_similarity))/
           (max(scale_similarity) - min(scale_similarity)),
         group_type = case_when(str_detect(subject_id, "CB_")~ "CB",
                                str_detect(subject_id, "S_")~ "S",
                                str_detect(subject_id, "AMT_")~ "AMT"),
         group_type = fct_recode(group_type, "Sighted" = "S", "Blind" = "CB", "Turk" = "AMT"))
```

We analyzed the 15 "light emission" verbs used by Bedny et al. (2019). We selected this set of items because they refer to a domain which blind participants have most limited direct perceptual access to. The 15 items are: `r  unique(c(sim_ratings$word1, sim_ratings$word2))`. We estimated the pairwise similarity of these words from distributional semantics (cosine distance) using a model trained on English Wikipedia (Bojanowski, et al. 2016), and then compared these distances to human similarity judgements. 

Presented below are the correlations between human judgements (blind, sighted, and a sample from Mechanical Turk; from Bedny et al., 2019) and estimates from the language model. The red points indicate pairs that include the item "blink," which appears to be an outlier -- presumably because blink also has a frequent sense that doesn't refer to light emission (i.e., a blinking eye). In the Main Text, we report correlation values with this item excluded; below are all correlation values with and without this item.

```{r, fig.height = 3.5}
mean_ratings <- sim_ratings %>%
  group_by(group_type, word1, word2) %>%
  filter(!is.na(norm_similarity)) %>%
  summarize(similarity = mean(norm_similarity)) 

# get language distances
LANGUAGE_DISTANCES <- here("data/processed/bedny_2019_lang_distances.csv")
long_word_word_dists <- read_csv(LANGUAGE_DISTANCES)

all_data <- mean_ratings %>%
  left_join(long_word_word_dists) %>%
  mutate(is_blink = case_when(word1 == "blink"| word2 == "blink" ~ "b", TRUE ~ "nb"))

ggplot(all_data, aes(x = language_similarity, y = similarity))+
  geom_point(aes(color = is_blink)) + 
  scale_color_manual(values = c("red", "black")) +
  xlab("Language Similarity (Wikipedia Corpus)") +
  ylab("Human Similarity")+
  geom_smooth(method = "lm") +
  facet_grid(~group_type) + 
  theme_classic() +
  theme(legend.position = "none")
```

Correlations with all items:
```{r}
all_data %>%
  rename(participant_group = group_type) %>%
  group_by(participant_group)%>%
  nest() %>%
  mutate(temp = map(data, ~tidy(cor.test(.$similarity, .$language_similarity,  method = "spearman")))) %>%
  select(-data) %>%
  unnest() %>%
  kable(digits = c(NA,2,1,8,NA,NA))
```

Correlations with "blink" excluded: 
```{r}
all_data %>%
  filter(is_blink == "nb") %>%
  rename(participant_group = group_type) %>%
  group_by(participant_group)%>%
  nest() %>%
  mutate(temp = map(data, ~tidy(cor.test(.$similarity, .$language_similarity,  method = "spearman")))) %>%
  select(-data) %>%
  unnest() %>%
  kable(digits = c(NA,2,1,9,NA,NA))
```

```{r}
b_vs_s <- all_data %>%
  filter(is_blink == "nb") %>%
  select(group_type, word1, word2, similarity) %>%
  spread(group_type, similarity)

b_vs_s_cor <- cor.test(b_vs_s$Blind, b_vs_s$Sighted, method = "spearman") %>%
  tidy() %>%
  mutate_if(is.numeric, round, 2)
```

Excluding "blink", the correlation between blind and sighted participants is $\rho$ = `r pull(b_vs_s_cor, estimate)` (_p_ < .01).

**References**

Bedny M., Koster-Hale J., Elli G., Yazzolino L., Saxe R. (2019) There’s more to “sparkle” than meets the eye: Knowledge of vision and light verbs among congenitally blind and sighted individuals.  _Cognition_ 189:105–115.

Bojanowski, P., Grave, E., Joulin, A., & Mikolov, T. (2016). Enriching word vectors with subword information. https://arxiv.org/abs/1607.04606

de Vries, A.  &  Ripley, B. D. (2016). ggdendro: Create Dendrograms and Tree Diagrams Using 'ggplot2'. R package version 0.1-20. https://CRAN.R-project.org/package=ggdendro

Galili, T. (2015). dendextend: an R package for visualizing, adjusting, and comparing trees of hierarchical clustering. Bioinformatics. DOI: 10.1093/bioinformatics/btv428

Mikolov, T., Chen, K., Corrado, G., & Dean, J. (2013). Efficient estimation of word representations in vector space. _arXiv preprint arXiv:1301.3781_.
